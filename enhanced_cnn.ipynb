{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T18:32:41.301638Z",
     "iopub.status.busy": "2025-04-05T18:32:41.301339Z",
     "iopub.status.idle": "2025-04-05T19:58:20.263543Z",
     "shell.execute_reply": "2025-04-05T19:58:20.262467Z",
     "shell.execute_reply.started": "2025-04-05T18:32:41.301615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Balanced dataset size: 76076\n",
      "\n",
      "Training Model 1 with seed 42\n",
      "Model 1, Epoch 1, Loss: 0.6364, Test Acc: 0.8352\n",
      "Model 1, Epoch 2, Loss: 0.2985, Test Acc: 0.8993\n",
      "Model 1, Epoch 3, Loss: 0.2420, Test Acc: 0.9088\n",
      "Model 1, Epoch 4, Loss: 0.1831, Test Acc: 0.8910\n",
      "Model 1, Epoch 5, Loss: 0.1436, Test Acc: 0.9055\n",
      "Model 1, Epoch 6, Loss: 0.1100, Test Acc: 0.8941\n",
      "Model 1 Early stopping at epoch 6, Best Acc: 0.9088\n",
      "\n",
      "Training Model 2 with seed 43\n",
      "Model 2, Epoch 1, Loss: 0.4883, Test Acc: 0.8583\n",
      "Model 2, Epoch 2, Loss: 0.2679, Test Acc: 0.9050\n",
      "Model 2, Epoch 3, Loss: 0.2259, Test Acc: 0.9063\n",
      "Model 2, Epoch 4, Loss: 0.1625, Test Acc: 0.9120\n",
      "Model 2, Epoch 5, Loss: 0.1200, Test Acc: 0.9040\n",
      "Model 2, Epoch 6, Loss: 0.0854, Test Acc: 0.9053\n",
      "Model 2, Epoch 7, Loss: 0.0335, Test Acc: 0.8968\n",
      "Model 2 Early stopping at epoch 7, Best Acc: 0.9120\n",
      "\n",
      "Training Model 3 with seed 44\n",
      "Model 3, Epoch 1, Loss: 0.6434, Test Acc: 0.8557\n",
      "Model 3, Epoch 2, Loss: 0.2866, Test Acc: 0.9039\n",
      "Model 3, Epoch 3, Loss: 0.2380, Test Acc: 0.8925\n",
      "Model 3, Epoch 4, Loss: 0.1789, Test Acc: 0.9094\n",
      "Model 3, Epoch 5, Loss: 0.1347, Test Acc: 0.9092\n",
      "Model 3, Epoch 6, Loss: 0.0929, Test Acc: 0.8993\n",
      "Model 3, Epoch 7, Loss: 0.0337, Test Acc: 0.9037\n",
      "Model 3 Early stopping at epoch 7, Best Acc: 0.9094\n",
      "\n",
      "Evaluating Ensemble...\n",
      "Ensemble Test Accuracy: 0.9112\n",
      "Ensemble Precision: 0.8986, Recall: 0.9283\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import string\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "data_path = '/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json'\n",
    "data = pd.read_json(data_path, lines=True, nrows=200000)\n",
    "data['target'] = data['stars'].map(lambda x: 0 if x <= 2 else 1)\n",
    "data = data[['text', 'target']]\n",
    "min_class_size = min(data['target'].value_counts())  # 38,038\n",
    "data_balanced = (data.groupby('target', group_keys=False)[['text', 'target']]\n",
    "                 .apply(lambda x: x.sample(n=min_class_size, random_state=42))\n",
    "                 .reset_index(drop=True))\n",
    "print(f\"Balanced dataset size: {len(data_balanced)}\")\n",
    "\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{} \\n\"\n",
    "char_to_idx = {char: idx + 1 for idx, char in enumerate(alphabet)}\n",
    "vocab_size = len(alphabet) + 1  # 71\n",
    "def text_to_indices(text, max_len=1014):\n",
    "    indices = [char_to_idx.get(c, 0) for c in str(text.lower())[:max_len]]\n",
    "    indices = [min(i, 69) for i in indices]\n",
    "    return indices + [0] * (max_len - len(indices))\n",
    "data_balanced['indices'] = data_balanced['text'].apply(text_to_indices)\n",
    "\n",
    "# Split data\n",
    "X = list(data_balanced['indices'])\n",
    "y = list(data_balanced['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "class ImprovedCharCNN(nn.Module):\n",
    "    def __init__(self, vocab_size=71, embed_dim=128, num_filters=1024):\n",
    "        super(ImprovedCharCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.conv1 = nn.Conv1d(embed_dim, num_filters, kernel_size=7, padding=3)\n",
    "        self.conv2 = nn.Conv1d(num_filters, num_filters, kernel_size=7, padding=3)\n",
    "        self.conv3 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv1d(num_filters, num_filters, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(num_filters * 37, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).transpose(1, 2)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = torch.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "models = []\n",
    "seeds = [42, 43, 44]\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"\\nTraining Model {i+1} with seed {seed}\")\n",
    "    torch.manual_seed(seed)\n",
    "    model = ImprovedCharCNN(vocab_size=vocab_size).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience = 3\n",
    "    trigger = 0\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        test_preds, test_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs).squeeze()\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "                test_preds.extend(preds.cpu().tolist())\n",
    "                test_true.extend(labels.cpu().tolist())\n",
    "        test_acc = accuracy_score(test_true, test_preds)\n",
    "        print(f'Model {i+1}, Epoch {epoch+1}, Loss: {avg_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            trigger = 0\n",
    "            torch.save(model.state_dict(), f'model_{i+1}_seed_{seed}.pth')\n",
    "        else:\n",
    "            trigger += 1\n",
    "            if trigger >= patience:\n",
    "                print(f'Model {i+1} Early stopping at epoch {epoch+1}, Best Acc: {best_acc:.4f}')\n",
    "                break\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    models.append(model)\n",
    "\n",
    "print(\"\\nEvaluating Ensemble...\")\n",
    "ensemble_preds, test_true = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = [torch.sigmoid(model(inputs).squeeze()) for model in models]\n",
    "        avg_outputs = torch.mean(torch.stack(outputs), dim=0) \n",
    "        preds = (avg_outputs > 0.5).long()\n",
    "        ensemble_preds.extend(preds.cpu().tolist())\n",
    "        test_true.extend(labels.cpu().tolist())\n",
    "\n",
    "ensemble_acc = accuracy_score(test_true, ensemble_preds)\n",
    "ensemble_precision = precision_score(test_true, ensemble_preds)\n",
    "ensemble_recall = recall_score(test_true, ensemble_preds)\n",
    "print(f'Ensemble Test Accuracy: {ensemble_acc:.4f}')\n",
    "print(f'Ensemble Precision: {ensemble_precision:.4f}, Recall: {ensemble_recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 10100,
     "sourceId": 3316532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
